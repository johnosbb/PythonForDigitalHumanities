{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed 3 documents\n",
      "Query:: hatstand\n",
      "\t [{'id': '2', 'title': 'Second document <b class=\"match term0\">hatstand</b>', 'description': 'The second one is even more interesting!', 'tags': ['alice'], 'extra': 'foals and horses'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: banana\n",
      "\t [{'id': '1', 'title': 'First document <b class=\"match term0\">banana</b>', 'description': \"This is the first document we've added in San Francisco!\", 'tags': ['foo', 'bar'], 'extra': 'kittens and cats'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: first\n",
      "\t [{'id': '1', 'title': '<b class=\"match term0\">First</b> document banana', 'description': 'This is the <b class=\"match term1\">first</b> document we\\'ve added', 'tags': ['foo', 'bar'], 'extra': 'kittens and cats'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: second\n",
      "\t [{'id': '2', 'title': '<b class=\"match term0\">Second</b> document hatstand', 'description': 'The <b class=\"match term1\">second</b> one is even more interesting', 'tags': ['alice'], 'extra': 'foals and horses'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: alice\n",
      "\t [{'id': '2', 'title': 'Second document hatstand', 'description': 'The second one is even more interesting!', 'tags': ['alice'], 'extra': 'foals and horses'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: bob\n",
      "\t [{'id': '3', 'title': 'Third document slug', 'description': 'The third one is less interesting!', 'tags': ['bob'], 'extra': 'bunny and rabbit'}]\n",
      "----------------------------------------------------------------------\n",
      "Query:: san francisco\n",
      "\t [{'id': '1', 'title': 'First document banana', 'description': 'we\\'ve added in <b class=\"match term0\">San</b> <b class=\"match term1\">Francisco</b>', 'tags': ['foo', 'bar'], 'extra': 'kittens and cats'}]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Sequence\n",
    "\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import MultifieldParser\n",
    "from whoosh.filedb.filestore import RamStorage\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "\n",
    "import json\n",
    "\n",
    "#\n",
    "# Simple example indexing to an in-memory index and performing a search\n",
    "# across multiple fields and returning an array of highlighted results.\n",
    "#\n",
    "# One lacking feature of Whoosh is the no-analyze option. In this example\n",
    "# the SearchEngine modifies the given schema and adds a RAW field. When doc\n",
    "# are added to the index only stored fields in the schema are passed to Whoosh\n",
    "# along with json encoded version of the whole doc stashed in the RAW field.\n",
    "#\n",
    "# On query the <Hit> in the result is ignored and instead the RAW field is\n",
    "# decoded containing any extra fields present in the original document. \n",
    "#\n",
    "\n",
    "\n",
    "class SearchEngine:\n",
    "\n",
    "    def __init__(self, schema):\n",
    "        self.schema = schema\n",
    "        schema.add('raw', TEXT(stored=True))\n",
    "        self.ix = RamStorage().create_index(self.schema)\n",
    "\n",
    "    def index_documents(self, docs: Sequence):\n",
    "        writer = self.ix.writer()\n",
    "        for doc in docs:\n",
    "            d = {k: v for k,v in doc.items() if k in self.schema.stored_names()}\n",
    "            d['raw'] = json.dumps(doc) # raw version of all of doc\n",
    "            writer.add_document(**d)\n",
    "        writer.commit(optimize=True)\n",
    "\n",
    "    def get_index_size(self) -> int:\n",
    "        return self.ix.doc_count_all()\n",
    "\n",
    "    def query(self, q: str, fields: Sequence, highlight: bool=True) -> List[Dict]:\n",
    "        search_results = []\n",
    "        with self.ix.searcher() as searcher:\n",
    "            results = searcher.search(MultifieldParser(fields, schema=self.schema).parse(q))\n",
    "            for r in results:\n",
    "                d = json.loads(r['raw'])\n",
    "                if highlight:\n",
    "                    for f in fields:\n",
    "                        if r[f] and isinstance(r[f], str):\n",
    "                            d[f] = r.highlights(f) or r[f]\n",
    "\n",
    "                search_results.append(d)\n",
    "\n",
    "        return search_results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    docs = [\n",
    "        {\n",
    "            \"id\": \"1\",\n",
    "            \"title\": \"First document banana\",\n",
    "            \"description\": \"This is the first document we've added in San Francisco!\",\n",
    "            \"tags\": ['foo', 'bar'],\n",
    "            \"extra\": \"kittens and cats\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"2\",\n",
    "            \"title\": \"Second document hatstand\",\n",
    "            \"description\": \"The second one is even more interesting!\",\n",
    "            \"tags\": ['alice'],\n",
    "            \"extra\": \"foals and horses\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"3\",\n",
    "            \"title\": \"Third document slug\",\n",
    "            \"description\": \"The third one is less interesting!\",\n",
    "            \"tags\": ['bob'],\n",
    "            \"extra\": \"bunny and rabbit\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    schema = Schema(\n",
    "        id=ID(stored=True),\n",
    "        title=TEXT(stored=True),\n",
    "        description=TEXT(stored=True, analyzer=StemmingAnalyzer()),\n",
    "        tags=KEYWORD(stored=True)\n",
    "    )\n",
    "\n",
    "    engine = SearchEngine(schema)\n",
    "    engine.index_documents(docs)\n",
    "\n",
    "    print(f\"indexed {engine.get_index_size()} documents\")\n",
    "\n",
    "    fields_to_search = [\"title\", \"description\", \"tags\"]\n",
    "\n",
    "    for q in [\"hatstand\", \"banana\", \"first\", \"second\", \"alice\", \"bob\", \"san francisco\"]:\n",
    "        print(f\"Query:: {q}\")\n",
    "        print(\"\\t\", engine.query(q, fields_to_search, highlight=True))\n",
    "        print(\"-\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
