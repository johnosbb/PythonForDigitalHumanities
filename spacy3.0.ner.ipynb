{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martha PERSON\n",
      "Spain GPE\n",
      "basketball SPORT\n",
      "June 2022 DATE\n",
      "soccer SPORT\n",
      "15 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "text= \"Martha, a senior, moved to Spain where she will be playing basketball until June 2022 or until she can't play any longer. She previously played soccer and made the national under 15 team.\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"SPORT\", \"pattern\" : \"basketball\"},{\"label\": \"SPORT\", \"pattern\" : \"soccer\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "    \n",
    "nlp.to_disk(\"./NER_Models/sports_ner\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jul 11 LAW\n",
      "16:38:47 TIME\n",
      "Workspace_Management COMPONENT\n",
      "workspace COMPONENT\n",
      "5 CARDINAL\n",
      "workspace COMPONENT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "text= \"Jul 11 16:38:47 snuc-sdkvm app.py: Workspace_Management: Terminating workspace 5 /workspace - new workspace\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"COMPONENT\", \"pattern\" : \"workspace\"},{\"label\": \"COMPONENT\", \"pattern\" : \"Workspace_Management\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "    \n",
    "nlp.to_disk(\"./NER_Models/syslog_a_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martha PERSON\n",
      "Spain GPE\n",
      "basketball SPORT\n",
      "June 2022 DATE\n",
      "soccer SPORT\n",
      "15 CARDINAL\n",
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "text= \"Martha, a senior, moved to Spain where she will be playing basketball until June 2022 or until she can't play any longer. She previously played soccer and made the national under 15 team.\"\n",
    "nlp=spacy.load(\"./NER_Models/sports_ner\")\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/johnos/PythonForDigitalHumanities\n",
      "['Status', 'Management', 'client', 'OSD']\n",
      "[{'label': 'COMPONENT', 'pattern': 'Status'}, {'label': 'COMPONENT', 'pattern': 'Management'}, {'label': 'COMPONENT', 'pattern': 'client'}, {'label': 'COMPONENT', 'pattern': 'OSD'}]\n",
      "['syslog_ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    " \n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_dir)\n",
    "\n",
    "# format of Spacy yTraining Data\n",
    "# TRAIN_DATA = [(text, {\"entities\": [(start,end,label)]})]\n",
    "\n",
    "def save_data(file,data):\n",
    "    with open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data,f, indent=4)\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)  \n",
    "\n",
    "data = load_data(\"ReferenceFiles/syslog_entities.json\")\n",
    "print(data)\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, text):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        #results.append((ent.start_char,ent.end_char, ent.label))\n",
    "        something = ((ent.start_char,ent.end_char, ent.label))\n",
    "        print(something)\n",
    "        \n",
    "    return (results)  \n",
    "\n",
    "\n",
    "def create_training_data(file,type):\n",
    "    data = load_data(file)\n",
    "    patterns = []\n",
    "    for item in data:\n",
    "        pattern = {\"label\" : type , \"pattern\" : item} # this is what spacy expects\n",
    "        patterns.append(pattern)\n",
    "    return patterns    \n",
    "        \n",
    "        \n",
    "def generate_rules(nlp,patterns):\n",
    "    entity_ruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "    nlp.add_pipe(\"ner\", name=\"syslog_ner\")\n",
    "    entity_ruler.add_patterns(patterns)\n",
    "    nlp.to_disk(\"./NER_Models/syslog_b_ner\")\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")            \n",
    "patterns = create_training_data(\"ReferenceFiles/syslog_entities.json\",\"COMPONENT\") \n",
    "print(patterns)\n",
    "generate_rules(nlp,patterns)  \n",
    "\n",
    "\n",
    "print(nlp.pipe_names)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jul 11 LAW\n",
      "16:38:47 TIME\n",
      "Workspace_Management COMPONENT\n",
      "workspace COMPONENT\n",
      "5 CARDINAL\n",
      "workspace COMPONENT\n",
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import os\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "def test_model(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        #results.append((ent.start_char,ent.end_char, ent.label))\n",
    "        something = ((ent.start_char,ent.end_char, ent.label))\n",
    "        print(something)\n",
    "        \n",
    "    return (results)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"./NER_Models/syslog_a_ner\")\n",
    "# with open(\"ReferenceFiles/syslog\", \"r\") as f:\n",
    "text= \"Jul 11 16:38:47 snuc-sdkvm app.py: Workspace_Management: Terminating workspace 5 /workspace - new workspace\"\n",
    "#     text = f.read()\n",
    "doc = nlp(text)    \n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "print(spacy.__version__)    \n",
    "#test_model(nlp, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Python', 'SKILL'), ('MySQL', 'SKILL'), ('Pandas', 'SKILL'), ('Spacy', 'SKILL'), ('Tensor Flow', 'SKILL')]\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'entity_ruler', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "entity_ruler = EntityRuler(nlp)\n",
    "nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "ruler = nlp.get_pipe('entity_ruler')\n",
    "\n",
    "skills = [\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"python\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"sql\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"mysql\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"pandas\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"spacy\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"scikit-learn\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"scikit\"}, {\"lower\": \"learn\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"sklearn\"}]},\n",
    "    {'label': 'SKILL', 'pattern': [{\"lower\": \"tensor\"}, {\"lower\": \"flow\"}]},\n",
    "]\n",
    "\n",
    "ruler.add_patterns(skills)\n",
    "\n",
    "text = \"\"\"\n",
    "We are looking for a data scientist with knowledge of Python and MySQL. \n",
    "The role will involve working with Pandas, scikit-learn, and Spacy.\n",
    "Knowledge of Tensor Flow would be advantageous.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(entities)\n",
    "print(nlp.pipe_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['ner']\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# You can generate a base config here: https://spacy.io/usage/training#config\n",
    "nlp = spacy.blank(\"en\") # a blank model\n",
    "print(nlp.pipe_names)\n",
    "nlp.add_pipe(\"ner\") # just the ner model\n",
    "print(nlp.pipe_names)\n",
    "nlp = spacy.load(\"en_core_web_sm\") #the standard small english model\n",
    "print(nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'syslog_ner', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"ner\", name=\"syslog_ner\", before=\"lemmatizer\") # we can position our pipe before or after other components\n",
    "print(nlp.pipe_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
