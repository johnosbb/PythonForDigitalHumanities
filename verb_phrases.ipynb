{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, `Oh dear!  \n",
      "her feel very\n",
      "eyes ran close\n",
      "all seemed quite\n",
      "hole went straight\n",
      "she fell very\n",
      "she said aloud\n",
      "she began again\n",
      "she walked sadly\n",
      "she went back\n",
      "you drink much\n",
      "she went back\n",
      "there's hardly\n",
      "it seemed quite\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "with open(\"./ReferenceFiles/alice.txt\") as f:\n",
    "    text =f.read().replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    chapters = text.split(\"CHAPTER \")[1:]\n",
    "chapter1 = chapters[0]\n",
    "#print(chapter1)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(chapter1)\n",
    "sentences = list(doc.sents)\n",
    "sentence = (sentences[2])\n",
    "print(sentence)\n",
    "\n",
    "\n",
    "patterns = [[{\"POS\": \"NOUN\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADV\"}],[{\"POS\": \"PRON\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADV\"}]]\n",
    "verb_phrases = textacy.extract.token_matches(doc, patterns)\n",
    "for verb_phrase in verb_phrases:\n",
    "    print(verb_phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was be\n",
      "think think\n",
      "hear hear\n",
      "say say\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "with open(\"./ReferenceFiles/alice.txt\") as f:\n",
    "    text =f.read().replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    chapters = text.split(\"CHAPTER \")[1:]\n",
    "chapter1 = chapters[0]\n",
    "#print(chapter1)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(chapter1)\n",
    "sentences = list(doc.sents)\n",
    "sentence = (sentences[2])\n",
    "for word in sentence:\n",
    "    if word.pos_ == \"VERB\":\n",
    "        print(word,word.lemma_)\n",
    "\n",
    "\n",
    "# patterns = [[{\"POS\": \"NOUN\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADV\"}],[{\"POS\": \"PRON\"}, {\"POS\": \"VERB\"}, {\"POS\": \"ADV\"}]]\n",
    "# verb_phrases = textacy.extract.token_matches(doc, patterns)\n",
    "# for verb_phrase in verb_phrases:\n",
    "#     print(verb_phrase)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
